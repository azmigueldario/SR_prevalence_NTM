---
title: "Analysis: systematic review of nontuberculous mycobacteria prevalence in cystic fibrosis"
author: "MDP"
output: 
  html_document:
    toc: true
    toc_depth: 2
    theme: united
    number_sections: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=F)
```

# Introduction

Our systematic review is a comprehensive picture of all studies and registry reports that include prevalence/incidence of _nontuberculous mycobacteria (NTM) in cystic fibrosis_ population

The analysis will be performed in R (v4.1.1) with __Github__ version control repository.We will analyze the prevalence as a proportion and the incidence as a rate, depending on availability in results. The data from the study cohort is saved in the `input` directory as a `.csv` file. 

### Aims
1. Explore our data and summarize it briefly
2. Explore publication bias and produce plots
3. Conduct meta-analysis of selected studies and produce summary plots
4. Perform pre-specified subgroup analysis
5. Conduct exploratory sensitivity analysis, meta regression and hierarchical analysis

# Data wrangling

Load required packages

- `dmetar` with its associated packages for some helpful functions 
- `meta` and `metafor` for meta-analysis, funnel plots, forest plots and meta-regression
- `knitr` allows us to produce nicely formatted tables in the report

```{r, warning=FALSE, message=FALSE}
# devtools::install_github("MathiasHarrer/dmetar")
packages <- c("dmetar", "meta", "metafor", "kableExtra", "gginnards", "tidyverse")
lapply(packages, library, character.only=T)
```

## Data import 

**Make sure to always check that it is the latest dataset.** 
We import the dataset and recode if they used registry.

```{r, message=FALSE}
temp <-  list()
temp$input <- 
  read_csv("./input/data_meta_analysis_qa.csv")  %>% 
  mutate(mabs_infection = as.numeric(mabs_infection),
         used_registry=fct_explicit_na(used_registry, "no"))

# table(temp$input$used_registry)
# glimpse(temp$input)
```

## Data wrangling

To produce quality plots, I create a variable in the form `Author YYYY`.

```{r study ID}
temp$untidy_data <-  
  temp$input %>% 
  mutate(study = gsub("([a-z])([0-9])", "\\1 \\2", id),
         # changes first letter to upper-case
         study = stringr::str_to_title(study))
```

Re-code study design under three categories, create a new variable that specifies those studies that used registry data and create an indicator variable for registry_reports

```{r wrangle study type}
table(temp$untidy_data$study_design)

temp$untidy_data<- 
  temp$untidy_data %>%
  mutate(study_design=case_when(study_design=="Cross-sectional study" ~ "Cross-sectional study",
                                study_design=="Registry report" ~ "Registry report",
                                TRUE ~ "Cohort study"),
         design_or_registry= case_when(study_design=="Registry report" | 
                                         used_registry!="no" ~ "Registry report/used registry",
                                       TRUE ~ study_design),
         is_registry=case_when(study_design=="Registry report" ~ 1,
                               TRUE ~ 0))

temp$untidy_data %>% 
  count(design_or_registry)

temp$untidy_data %>% 
  count(is_registry, study_design, design_or_registry) 
```

We create a grouping variable according to the first year of data collection of a study. We use 5-years intervals between 2000 and 2020

```{r date range groups}
temp$untidy_data<- 
  temp$untidy_data %>%
  mutate(before_year=case_when(first_year_data<2000 ~ "2000 or before",
                               first_year_data<=2004 ~ "2001-2004",
                               first_year_data<=2009 ~ "2005-2009",
                               first_year_data<=2014 ~ "2010-2014",
                               TRUE ~ "2015 or after")) 

count(temp$untidy_data, before_year) 
```

The variable `region` has few studies in AUS, ME, AFR & LAC. We group these in the _others_ category. 

```{r regions}
# table(temp$untidy_data$region)

temp$untidy_data <- 
  temp$untidy_data %>% 
  mutate(region1=case_when(region=="NAM"~"NAM",
                           region=="EUR"~"EUR",
                           TRUE ~ "Other"))

#count(temp$untidy_data, region1)
```

## Cleaning quality assessment data

Risk of bias plots require a special structure of the data.frame

- We standardize the Joanna Briggs appraisal tool for prevalence studies answers to COCHRANE coding `Yes=Low, No=High, Unclear=Unclear`
- Name of variables is explicit

```{r}
temp$untidy_data <- 
  temp$untidy_data %>% 
  mutate(across(starts_with("Q"), 
                ~ recode_factor (.x,
                                 `Yes`="Low",
                                 `Unclear`="Unclear",
                                 `No`="High",
                                 `Missing`="Missing")
                )) 
```

## Defining overall Risk of bias assessment

To conduct a sensitivity analysis based on overall risk of bias, we created the following definitions based on the author's considerations of the most important domains in quality appraisal:

+ **Low risk** requires _low risk in all of_ sampling frame, sampling scheme, sample size, population description and statistical calculation. Also, _must not be high risk_ in standardized outcome measurement.

+ **High risk** when qualified as _high risk in any_ of sampling frame, sampling scheme, sampling size,  population description, identification methods or statistical calculation

+ **Unclear** for remaining ones

```{r}
# save names of QA variables
temp$ROBcolnames<- 
  select(temp$untidy_data, contains("Q")) %>%
  colnames(); temp$ROBcolnames

temp$untidy_data <- 
  temp$untidy_data %>% 
  # shorten the names of QA variables
  rename_with(.cols = contains("Q"), 
              ~ gsub("^(Q[0-9]).*","\\1", .x)) %>%
  mutate(Overall_risk=
           case_when(Q1 == "High" | Q2 == "High" | Q3 == "High" | Q4 == "High" |
                       Q6 == "High" | Q8 == "High" ~ "High", 
                     # definition of high risk above
                     Q1 == "Low" & Q2 == "Low" & Q3 == "Low" & Q4 == "Low" & Q8 == "Low" &
                       Q7 != "High" ~ "Low", 
                     # definition of low risk above
                     TRUE ~ "Unclear")) %>%
  # rename with original names
  rename_with(.cols = matches("^Q"), ~ temp$ROBcolnames) 
```

The last step in data wrangling is to change all character variables into factors. 

```{r}
clean_data <-  
  temp$untidy_data %>%
  mutate(across(where(is.character), as_factor))

```

# Exploratory data analysis 

## Wrapper functions

__count_wrapper__ counts and produces a kable formatted table
__formatted_kable__ contains the styling steps to produce an html formatted table, requires a data input 

```{r kable wrapper}
count_table <- function(data, var) {
  count(data, {{var}}) %>%
    mutate(prop = prop.table(n)*100,
           prop = round(prop, 1)) %>%
    kbl(format="html", 
        align = c("lcc"), 
        digits = 2, 
        booktabs = T) %>%
    kable_styling(font_size = 25, 
                  bootstrap_options = "striped") %>% 
    kable_classic(full_width = F)
}

formatted_kable <- function(data, names=colnames(data)) {
  kbl(x=data, format="html", 
      align = c("lccccccccc"), 
      digits=2, 
      col.names = names) %>%
    kable_styling(font_size = 25, 
                  bootstrap_options = "striped") %>% 
    kable_classic(full_width = F)
}
```

- How many studies reported individual species data to calculate prevalence of MAC or MABs?

```{r}
clean_data %>% 
  count_table(is.na(mabs_infection))

clean_data %>% 
  count_table(is.na(avium_infection))
```


- How many studies are registry reports? 
- How many studies include pediatric, mixed or adult population ?  

```{r study types}
count_table(clean_data, study_design)

count_table(clean_data, age_group) 

# Excluding registry reports
filter(clean_data, is_registry==0) %>% 
  count_table(., age_group)
```

_ In what region where most of the studies conducted?

```{r region}
count_table(clean_data, region)
```

- Summarize the first year of data in the studies 
- What is the range of data_years included in the studies? 

```{r first year of data}

quantile(clean_data$first_year_data, na.rm = T) %>% data.frame(Quantiles=.) %>% 
  formatted_kable() 

ggplot(clean_data, aes(y=first_year_data, x=0)) +
  geom_boxplot(width=1.3, outlier.shape =NA) +
  geom_jitter(width = 0.2, color="grey37") +
  labs(title= "First year of data collected in study",
       subtitle = "All studies",
       y="") +
  theme_classic()+
  xlim(-1,1) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust=0.5),
        plot.subtitle = element_text(colour="red4"))

# excluding registry reports 
clean_data %>% 
  filter(is_registry==0) %>% 
  summarize(
    mean_year=mean(first_year_data, na.rm=T),
    sd=sd(first_year_data, na.rm=T),
    quantile_years= quantile(first_year_data, na.rm = T)
    ) %>% 
  formatted_kable()

clean_data %>% 
  filter(is_registry==0) %>% 
  ggplot(aes(y=first_year_data, x=0)) +
  stat_boxplot(geom = "errorbar", width=0.3) +
  geom_boxplot(width=1.3, outlier.shape =NA) +
  geom_jitter(width = 0.2, color="grey37") +
  labs(title= "First year of data collected in study",
       subtitle = "Excludes registry studies",
       y="") +
  theme_classic()+
  xlim(-1,1) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust=0.5, size=16),
        plot.subtitle = element_text(colour="red4", size=14))
```

- How many were conducted before 2010 and 2000?
    + We use the 5-year groups we previously defined to summarize this data. Before plotting, we organize in increasing order the factor variable.

```{r barplot by date range}

filter(clean_data, is_registry==0) %>%
  count_table(., before_year)

# relevel before_year factor
clean_data$before_year<- 
  factor(clean_data$before_year, levels = c("2000 or before","2001-2004","2005-2009","2010-2014","2015 or after")) 

clean_data %>% 
  filter(is_registry==0) %>%
  ggplot(aes(x=before_year, fill=factor(before_year)))+
  geom_bar() +
  labs(title= "Frequency of studies by date of data collection",
       subtitle = "No registry reports",
       x= "",
       y="") +
  scale_fill_brewer(palette = "Blues") +
  theme_classic()+
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size=16),
        plot.subtitle = element_text(color="red4", size=14),
        axis.text = element_text(size=12)) 
```

- What is the median sample size of the non-registry studies?
    + Does this change according to the year of data collection?

```{r sample size}
## for registry reports or registry based studies
clean_data %>% 
  filter(is_registry==1 | used_registry=="yes") %>% 
  summarize(
  SampleSize_quantiles=quantile(sample_size_cf, na.rm=T)) %>% 
  formatted_kable()

# observational studies
clean_data %>% 
  filter(is_registry==0 & used_registry=="no") %>% 
  summarize(
  sample_size_quantiles=quantile(sample_size_cf, na.rm=T)) %>%
  formatted_kable()

clean_data %>% 
  filter(is_registry==0 & used_registry=="no") %>% 
  ggplot(aes(y=sample_size_cf, x=first_year_data)) +
  geom_point(size=2) +
  labs (title="Sample size according to year of data",
       subtitle="No registry reports",
       x="First year of data collection",
       y="CF sample size (log10 scale)") +
  scale_y_continuous(trans="log10") +
  theme(plot.subtitle = element_text(color="red4", size = 14),
        plot.title = element_text(size=16, hjust=0.5),
        axis.text = element_text(size=12),
        axis.title = element_text(size=12)) 
```


### Wrapper: meta-analysis 

__metaprop_formatted__ wraps the `meta::metaprop` function with options 
 - `sm=PLOGIT` specifies to use the logit transformation for the proportions
 - `hakn=TRUE` applies an adjustment for more conservative confidence intervals
 - `comb.random=T` specified a random effects model
 - `method="GLMM"` recommended over inverse variance for proportions
 - `n=sample_size_cf` specified the variable with sample size
 - `event=all_ntm_infection` calls the number of events

```{r formatted meta.prop function}
metaprop_formatted <- function (data=data, fixed=F){
  metaprop(
    data=data,
    event = all_ntm_infection,
    n = sample_size_cf,
    studlab = study,
    method = "GLMM",
    sm = "PLOGIT",
    random = TRUE,
    fixed=fixed,
    hakn = TRUE)
}
```

### Wrapper: forest plot 
__forest_wrapper__ produces a forest plot with common formatting options. 

- `sortvar=data$TE,` specifies the sorting variable, default is the weight in the MA
- `predict=T` calculates prediction intervals instead of CI by default
- `comb.fixed = F` translates to random effects MA
- `print.I2.ci = T` forces printing of heterogeneity confidence intervals
- `study.results` determines if individual study results should be plotted, it does not by default
- `layout="RevMan5"` formats output according to RevMan5 style 
- `xlim` determines X-axis limit
- Automatically adds a row below estimates to improve plotting and adds space between columns

```{r formatted forest.meta }

forest_wrapper <- function(data, 
                           sort.var=data$TE, 
                           stu.res=F,
                           xlim=c(0,0.5), 
                           pred_int=T,
                           subgroup.name="", 
                           xlab="") {
  
  forest.meta(x=data,
              sortvar = sort.var,
              predict = pred_int,
              comb.fixed = F,
              layout="RevMan5",
              print.I2.ci = T,
              colgap.left = "2cm",
              colgap.forest = "1.5cm",
              rightcols = c("effect", "ci", "w.random"),
              study.results = stu.res,
              test.subgroup.random = T,
              addrow.subgroups = T,
              addrow = T,
              addrow.overall = T,
              col.by = "grey2",
              test.subgroup = T,
              xlab = xlab,
              xlim=xlim,
              addrows.below.overall = 1,
              subgroup.name = subgroup.name
  )
}
# forest_wrapper(meta.full)

```



## How many studies report every outcome

The dataset includes only raw numbers, percentages without raw numbers were not included. 

- **NTM disease**
    + Period prevalence = 13
    + Point prevalence = 2
- **NTM infection**
    + Incidence proportion = 4
    + Point prevalence = 56
    + Period prevalence = 43

```{r}
clean_data %>% 
  filter(!is.na(all_ntm_infection)) %>%
  mutate(point=case_when(last_year_data - first_year_data < 2 ~ "yes",
                         TRUE ~ "no" )) %>%
  count_table(point)
```

# Meta analysis of NTM infection point (annual) prevalence

## All studies meta-analysis

* Meta-analysis will be conducted only for point prevalence of NTM infection
    - `all_ntm_infection` which contains the number of events
    - `sample_size_cf` especifies the CF population
* For analysis, we create a dataset that includes only the set of studies to analyze

```{r}
inf_point_data <-  
  clean_data %>% 
  filter (!is.na(all_ntm_infection) &
           last_year_data - first_year_data < 2) 
# n= 57
```

In a meta-analysis including all studies, there is high heterogeneity. All observations cannot be plotted.  

```{r}
meta.full<- metaprop_formatted(inf_point_data)
forest_wrapper(meta.full)
```

## Subgroup: study design (registry or not) 

To produce subgroups we update `full.meta` according to a variable and then pass it to our `forest_wrapper` function to produce nice forest plots

```{r}
# Subgroup test is significant but not relevant change (98.3 vs 99.7)
update.meta(meta.full,
            subgroup = is_registry,
            tau.common = F)

# reduced heterogeneity according to study design, lower in cohort and cross sectional studies (82% & 91%) compared to registries (99.7%)
update.meta(meta.full,
            subgroup = design_or_registry,
            tau.common = F)

# forest plot for subgroup analysis by study_design
update.meta(meta.full,
            subgroup = study_design,
            tau.common = F) %>%
  forest_wrapper(data = .)

# forest plot for subgroup analysis grouping registry/used_registry together
update.meta(meta.full,
            subgroup = design_or_registry,
            tau.common = F) %>%
  forest_wrapper(data = .)

# removing data from Brazilian registry
inf_point_data %>%
  filter(used_registry != "Brazil") %>%
  metaprop_formatted() %>%
  update.meta(.,
              subgroup =  study_design,
              tau.common = F) %>%
  forest_wrapper()

```

### Separated forest plots for registry studies and observational studies

```{r}
# forest plots of registry studies with raw numbers
inf_point_data %>% 
  filter (is_registry==1) %>% 
  metaprop_formatted(data=.) %>% 
  forest_wrapper(data=., stu.res = T, xlim = c(0,0.3))

# * Only observational studies that did not use registry data
inf_point_data %>%
  filter (is_registry == 0) %>%
  metaprop_formatted(data = .) %>%
  forest_wrapper(data = .,
                 stu.res = T,
                 sort.var = .$studlab,
                 xlim = c(0, 0.35))

```

## Subgroup: year of data collection

```{r}
update.meta(meta.full,
            subgroup = before_year, 
            tau.common = F) %>%
  forest_wrapper(data=., 
                 pred_int = F, 
                 xlim=c(0,1), 
                 subgroup.name="First year of data collection")

```

We see reduced heterogeneity in the groups before 2000, 2001 - 2004 and 2005 - 2009. This difference is statistically significant. 

## Subgroup by regions (continents)

Others includes studies in Latin-America, Australia, Middle-East and Africa. 

```{r}
update.meta(meta.full,
            subgroup =  region1, 
            tau.common = F) %>% 
  forest_wrapper(data=., 
                 subgroup.name ="Region", 
                 pred_int = T, 
                 xlim = c(0,0.5))
    
```

There is a significant difference in the effect estimates among the groups, but heterogeneity remains high in all (>95%)

## Subgroup by age 

Not performed because more than 80% of the studies have a mixed (pediatric+adult) and more granular data could not be retrieved. 

# Additional analyses

## Meta-regression: including multiple moderators 

We use `metafor::rma.uni` function to fit the meta-analyses and indicate the moderators (grouping variables) to be used. 

Syntax options for moderators:
 - mods = cbind (mod1,mod2,mod3)
 - mods= ~ mod1 + mod2 + mod3


1. Calculate the effect size (proportions) using `escalc()` 
    + Reorder and format covariates
    + Our units are Logit-proportions **"PLO"** 
        ++ Better statistical properties _(Schwarzer 2019)_
    + All covariates are inside the `inf_point_data` object

```{r calculate proportion effect size}
# change reference level in factors
inf_point_data <- 
  inf_point_data %>% 
  mutate(region1=relevel(region1, ref="NAM"),
         before_year=relevel(before_year, ref="2015 or after"),
         study_design=relevel(study_design, ref="Registry report")) 


inf_point_escalc <-
  inf_point_data  %>% 
  escalc(data = .,
         xi=all_ntm_infection, # number of events
         ni=sample_size_cf,  # sample size
         measure="PLO")
```

2. Validate results between `meta` and `metafor`by fitting general meta-analysis
    + slab = study label
    + yi and vi are effect measures calculated by `escalc()`
    + method = REML

```{r metafor all studies MA}
metafor.full <- 
  rma.uni(yi = yi, 
          vi = vi, 
          slab = id,
          data = inf_point_escalc,
          test = "knha",
          method = "REML")

meta.full$TE.random %>% transf.ilogit()
coef(metafor.full) %>% transf.ilogit()

# provides roughly the same results
```

3. Fit a meta-regression model to evaluate the heterogeneity according to our pre-specified subgroups

```{r meta-regression}

metareg <- 
  rma.uni(yi = yi, 
          vi = vi,
          mods= ~ region1 + before_year + study_design +study_design*region1, 
          slab = id,
          data = inf_point_escalc,
          test = "knha",
          method = "REML")

# create vector with formatted names for coefficients
temp$coef.names <- c("Intercept", "Region:EUR", "Region:other", "2000 or before",
                     "2001-2004", "2005-2009", "2010-2014",
                     "Design:cross-sectional", "Design:cohort",
                     "EUR*Cross.sectional", "Other*Cross.sectional", 
                     "EUR*Cohort", "Other*Cohort")

# backtransform LOGIT proportions and produce table
summary(metareg) %>% 
  coef() %>% 
  mutate(Coefs=temp$coef.names,.before=1) %>%
  remove_rownames() %>% 
  # specify names of columns
  formatted_kable(names=c("Coefficients", "LOGIT-estimate", "std.error", 
                          "t-value", "df", "p.value", "CI-lower", "CI-upper")) %>%
  # bold significant rows
  row_spec(row=c(2,3,6,7,11,13), bold=T) %>% 
  kable_styling(font_size = 18)
```

## Exploratory: multilevel model

We explored inner collinerarity among registry studies in a multi-level meta-analysis with studies nested according to registry data they used

* `rma.mv()` fits multilevel meta-analysis 
    +`random = ~ 1 | a/b` specifies b nested in a
    +`random = ~ a | b ` specifies that a = inner group and b = outer group

```{r}
# table(inf_point_data$used_registry)

multilvl.meta <- 
  rma.mv(yi = yi, 
         V = vi,
         slab = id,
         data = inf_point_escalc,
         random = ~ 1 | used_registry/id,
         test = "t",
         method = "REML")

# produce table
data.frame(Estimate=transf.ilogit(multilvl.meta$beta),
           Lower_CI=transf.ilogit(multilvl.meta$ci.lb),
           Upper_CI=transf.ilogit(multilvl.meta$ci.ub)) %>% 
  formatted_kable()

summary(multilvl.meta)
transf.ilogit(-3.2488)
```

What percentage of the variance is explained by level of our hierarchical model. Level 3 groups according to registry. 

```{r}
var.comp(multilvl.meta)$results %>%
  mutate(Vars = c("Individual level", "Study/registry", "Registry"),
         n_groups = c("--", "73", "6"),
         .before = 1) %>%
  formatted_kable(names = c("", "n", "% of total variance", "$I^2$")) %>%
  row_spec(row = 0, bold = T) %>%
  kable_styling(font_size = 24)
```

## Exploratory: subgroup by overall quality

Low risk of bias studies have narrow prediction interval. 

```{r}
table(inf_point_data$Overall_risk)

update.meta(meta.full,
            subgroup =  Overall_risk, 
            tau.common = F)
# significant difference according to overall RoB appraisal. 

update.meta(meta.full,
            subgroup = Overall_risk, 
            tau.common = F) %>%
  forest_wrapper(subgroup.name = "Overall Risk of Bias (JBI)")
#  forest plot according to overall RoB

inf_point_data %>% 
  filter(Overall_risk=="Low") %>%
  metaprop_formatted(data=.) %>% 
  forest_wrapper(stu.res = T, xlim = c(0,0.3), sort.var = .$stulab)
# plot of only low RoB studies
  
```

# Complementary analyses for meta-analysis

## Publication bias (funnel plot)

For the meta-analysis of all studies (contour-enhanced funnel plot). There is asymmetry by Egger's test. 

```{r all studies funnel plot and egger's test}
funnel(x=metafor.full,
       xlab="Logit transformed proportions",
       level=c(90, 95, 99), 
       shade=c("white", "gray55", "gray75"),
       legend="topleft", 
       atransf = transf.ilogit)

regtest(metafor.full,
        model = "rma",
        predictor = "sei",
        ret.fit = T)

# for the metaregression 
regtest(metareg,
        model = "rma",
        predictor = "sei",
        ret.fit = T)

```

There is a significant p_value including all studies, and  we can see an asymmetry at the lower left side (low SE and small estimate). If we remove Brazilian registry reports, it disappears.

```{r excluding Brazil registry (funnel & egger's test)}

temp$maetafor_not_brazil <- 
inf_point_data  %>% 
  filter(used_registry!="Brazil") %>% 
  escalc(data = .,
         xi=all_ntm_infection, # number of events
         ni=sample_size_cf,  # sample size
         measure="PLO") %>%
  rma.uni(yi = yi,
          vi = vi,
          slab = id,
          data = .,
          test = "knha",
          method = "REML")


funnel(x=temp$maetafor_not_brazil,
       xlab="Logit transformed proportions",
       level=c(90, 95, 99), 
       shade=c("white", "gray55", "gray75"),
       legend="topleft", 
       atransf = transf.ilogit)

regtest(temp$maetafor_not_brazil,
        model = "rma",
        predictor = "sei",
        ret.fit = T)
```


## Publication bias (Trim & Fill method)

The trim and fill method detects places of asymmetry in the funnel plot and inputs studies to achieve a more balanced estimation. It is used to quantify the degree of small studies bias in our results. 

```{r}
trimfill(metafor.full)

# backtransform logit to proportion
transf.ilogit( -3.1667)
```

No study was imputed using these method and the estimate did not change at all. 


# Risk of bias appraissal

We will summarize the Quality assessment recorded from the Joanna Briggs tool. Unfortunately, there is no easy way to plot this in R and we have to create a new dataframe that fulfills the requirements of the available tools:

- First column for study labels named `study`
- Then, columns with risk of bias appraisal coded as Low/Unclear/High/Missing
- Overall quality in last column

```{r load robvis library, message=F}
# must be latest development version, used 0.3.0.900
# install.packages("devtools")
# devtools::install_github("mcguinlu/robvis")
library (robvis)
```

First, we select only the variables that contain quality assessment data and transform the data into a `data.frame` object.

```{r}
rob_data <- 
  clean_data %>% 
  select(study, matches("Q[0-9]"), Overall_risk, study_design, 
         before_year, period_disease, period_prevalence) %>% 
  rename(ROB_overall=Overall_risk) %>% 
  as.data.frame() 
```

## Summary plots

Now, we produce both plots summary tables using the rob.summary function from the `dmetar` package

* The function had a minor issue with the matching of the legend so I correct it in the source code as rob.summary2
 - All credit to authors, I will just use it locally

```{r rob.summary2}
rob.summary2 = function(data,
                       name.high="High",
                       name.unclear="Unclear",
                       name.low="Low",
                       studies,
                       name.missing,
                       table = FALSE){
  
  # Class Checks
  if (class(data) != "data.frame"){
    stop("'data' must be of class 'data.frame'.")
  }
  
  
  if (missing(name.missing)){
    
    # Only select columns with RoB data
    
    colnames.rob = character()
    
    for (i in 1:ncol(data)){
      
      vect = as.character(data[,i])
      
      for (j in 1:length(data[,i])){
        
        if (vect[j] %in% c(name.high, name.unclear, name.low)){
          
          colnames.rob[i] = TRUE
          
        } else {
          
          colnames.rob[i] = FALSE
          message(cat("Column '", colnames(data)[i],
                      "' removed from plot because it did not contain the specified RoB ratings (only). \n",
                      sep=""))
          break
          
        }
      }
    }
    
    # Use mask: rob data
    rob = data[ , as.logical(colnames.rob)]
    
    # Relevel for plot
    for (i in 1:ncol(rob)){
      
      rob[,i] = as.character(rob[,i])
      rob[rob[,i]==name.high,i] = "High"
      rob[rob[,i]==name.unclear,i] = "Unclear"
      rob[rob[,i]==name.low,i] = "Low"
      
    }
    
    # Make table
    if (table == TRUE){
      
      if (missing(studies)){
        stop("'studies' has to be specified when 'table = TRUE'.")
      }
      
      if (length(as.vector(studies)) != nrow(data)){
        stop("'studies' vector is not of equal length as the data.")
      }
      
      if (length(unique(studies)) != length(studies)){
        stop("'studies' cannot contain duplicate study labels.")
      }
      
      robby = rob
      robby = data.frame(study = studies,
                         condition = rep(colnames(robby), each = length(studies)),
                         measurement = unlist(robby))
      rownames(robby) = NULL
      robby$condition = gsub("_"," ", robby$condition)
      robby$condition = gsub("-"," ", robby$condition)
      robby$condition = gsub("\\."," ", robby$condition)
      robby[robby$measurement=="Low", "measurement"] = "+"
      robby[robby$measurement=="Unclear", "measurement"] = "?"
      robby[robby$measurement=="High", "measurement"] = "-"
      
      # Order factor
      robby$study = factor(robby$study,
                           levels = unique(studies)[rev(order(unique(robby$study)))])
      
      
      rob.table = ggplot(data = robby, aes(y = study, x = condition)) +
        geom_tile(color="black", fill="white", size = 0.8) +
        geom_point(aes(color=as.factor(measurement)), size=20) +
        geom_text(aes(label = measurement), size = 8) +
        scale_x_discrete(position = "top") +
        scale_color_manual(values = c("?" = "#E2DF07",
                                      "-" = "#BF0000",
                                      "+" = "#02C100")) +
        theme_minimal() +
        coord_equal() +
        theme(axis.title.x = element_blank(),
              axis.title.y = element_blank(),
              axis.ticks.y = element_blank(),
              axis.text.y = element_text(size = 15, color = "black"),
              axis.text.x = element_text(size = 13, color = "black", angle = 90, hjust=0),
              legend.position = "none",
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.background = element_blank())
      
    }
    
    # Make long format, clean the factors
    rob.long = data.frame(condition = rep(colnames(rob), each = nrow(rob)),
                          measurement = unlist(rob))
    rownames(rob.long) = NULL
    rob.long$condition = gsub("_"," ",rob.long$condition)
    rob.long$condition = gsub("-"," ",rob.long$condition)
    rob.long$condition = gsub("\\."," ",rob.long$condition)
    rob.long$measurement = as.factor(rob.long$measurement)
    rob.long$measurement = factor(rob.long$measurement, levels(rob.long$measurement)[c(1, 3, 2)])
    
    # Make plot
    rob.plot = ggplot(data = rob.long) +
      geom_bar(mapping = aes(x = condition, fill = measurement), width = 0.7,
               position = "fill", color = "black") +
      coord_flip(ylim = c(0, 1)) +
      guides(fill = guide_legend(reverse = TRUE)) +
      scale_fill_manual("Risk of Bias",
                        labels = c("    Unclear risk of bias       ",
                                   "    High risk of bias          ",
                                   "    Low risk of bias  "),
                        values = c(Unclear = "#E2DF07", High = "#BF0000", Low = "#02C100")) +
      scale_y_continuous(labels = scales::percent) +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.text.y = element_text(size = 18, color = "black"),
            axis.line.x = element_line(colour = "black", size = 0.5, linetype = "solid"),
            legend.position = "bottom",
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.background = element_rect(linetype = "solid", colour = "black"),
            legend.title = element_blank(),
            legend.key.size = unit(0.75, "cm"),
            legend.text = element_text(size = 14))
    
    plot(rob.plot)
    
    if (table == TRUE){
      plot(rob.table)
    }
    
  } else {
    
    # Only select columns with RoB data
    data = as.data.frame(data)
    
    colnames.rob = character()
    
    for (i in 1:ncol(data)){
      
      vect = as.character(data[,i])
      
      for (j in 1:length(data[,i])){
        
        if (vect[j] %in% c(name.high, name.unclear, name.low, name.missing)){
          
          colnames.rob[i] = TRUE
          
        } else {
          
          colnames.rob[i] = FALSE
          message(cat("Column '", colnames(data)[i],
                      "' removed from plot because it did not contain the specified RoB ratings (only). \n",
                      sep=""))
          break
          
        }
      }
    }
    
    # Use mask: rob data
    rob = data[ , as.logical(colnames.rob)]
    
    # Relevel for plot
    for (i in 1:ncol(rob)){
      
      rob[,i] = as.character(rob[,i])
      rob[rob[,i]==name.high,i] = "High"
      rob[rob[,i]==name.unclear,i] = "Unclear"
      rob[rob[,i]==name.low,i] = "Low"
      rob[rob[,i]==name.missing,i] = "Missing"
      
    }
    
    # Make Table
    
    if (table == TRUE){
      
      if (missing(studies)){
        stop("'studies' has to be specified when 'table = TRUE'.")
      }
      
      if (length(as.vector(studies)) != nrow(data)){
        stop("'studies' vector is not of equal length as the data.")
      }
      
      robby = rob
      robby = data.frame(study = as.factor(studies),
                         condition = rep(colnames(robby), each = length(studies)),
                         measurement = unlist(robby))
      rownames(robby) = NULL
      robby$condition = gsub("_"," ", robby$condition)
      robby$condition = gsub("-"," ", robby$condition)
      robby$condition = gsub("\\."," ", robby$condition)
      robby[robby$measurement=="Low", "measurement"] = "+"
      robby[robby$measurement=="Unclear", "measurement"] = "?"
      robby[robby$measurement=="High", "measurement"] = "-"
      robby[robby$measurement=="Missing", "measurement"] = " "
      
      # Order factor
      robby$study = factor(robby$study,
                           levels = unique(studies)[rev(order(unique(robby$study)))])
      
      rob.table = ggplot(data = robby, aes(y = study, x = condition)) +
        geom_tile(color="black", fill="white", size = 0.8) +
        geom_point(aes(color=as.factor(measurement)), size=20) +
        geom_text(aes(label = measurement), size = 8) +
        scale_x_discrete(position = "top") +
        scale_color_manual(values = c("?" = "#E2DF07",
                                      "-" = "#BF0000",
                                      "+" = "#02C100",
                                      " " = "white")) +
        theme_minimal() +
        coord_equal() +
        theme(axis.title.x = element_blank(),
              axis.title.y = element_blank(),
              axis.ticks.y = element_blank(),
              axis.text.y = element_text(size = 15, color = "black"),
              axis.text.x = element_text(size = 13, color = "black", angle = 90, hjust=0),
              legend.position = "none",
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.background = element_blank())
      
    }
    
    
    # Make long format, clean the factors
    rob.long = data.frame(condition = rep(colnames(rob), each = nrow(rob)),
                          measurement = unlist(rob))
    rownames(rob.long) = NULL
    rob.long$condition = gsub("_"," ",rob.long$condition)
    rob.long$condition = gsub("-"," ",rob.long$condition)
    rob.long$condition = gsub("\\."," ",rob.long$condition)
    rob.long$measurement = as.factor(rob.long$measurement)
    rob.long$measurement = factor(rob.long$measurement, levels(rob.long$measurement)[c(3,1,4,2)])
    
    rob.plot = ggplot(data = rob.long) +
      geom_bar(mapping = aes(x = condition, fill = measurement), width = 0.7,
               position = "fill", color = "black") +
      coord_flip(ylim = c(0, 1)) +
      guides(fill = guide_legend(reverse = TRUE)) +
      scale_fill_manual("Risk of Bias",
                        labels = c("  Unclear risk of bias  ",
                                   "  High risk of bias   ",
                                   "  Low risk of bias  ",
                                   "  Missing information  "),
                        values = c(Unclear = "#E2DF07",
                                   High = "#BF0000",
                                   Low = "#02C100",
                                   Missing = "white")) +
      scale_y_continuous(labels = scales::percent) +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.text.y = element_text(size = 18, color = "black"),
            axis.line.x = element_line(colour = "black", size = 0.5, linetype = "solid"),
            legend.position = "bottom",
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.background = element_rect(linetype = "solid", colour = "black"),
            legend.title = element_blank(),
            legend.key.size = unit(0.75, "cm"),
            legend.text = element_text(size = 14))
    
    plot(rob.plot)
    
    if (table == TRUE){
      plot(rob.table)
    }
    
  }
  
}

```


All studies inside the summary

```{r}
rob_data %>%
  select(-ROB_overall) %>% 
  rob.summary2(data=.,
              name.high="High",
              name.unclear="Unclear",
              name.low="Low",
              name.missing ="Missing",
              studies=.$study) 

```

Registry studies vs others

```{r}
rob_data %>%
  filter(study_design=="Registry report") %>% 
  select(-ROB_overall) %>% 
  rob.summary2(data=.,
              name.high="High",
              name.unclear="Unclear",
              name.low="Low",
              name.missing ="Missing",
              studies=.$study)

rob_data %>%
  filter(study_design!="Registry report") %>% 
  select(-ROB_overall) %>% 
  rob.summary2(data=.,
              name.high="High",
              name.unclear="Unclear",
              name.low="Low",
              name.missing ="Missing",
              studies=.$study)

```

## Traffic light plots

We summarize as subgroups to avoid crowding in the plot, so I produce first traffic plots for all registry reports. 

* Using the `delete_layers()` I remove automatically generated layers so they are not seen in the background
* Then, I add the table layout, color squares and text to produce the traffic light

```{r}

traffic_plots <- list()
traffic_plots$reg_a <- 
  rob_data %>%
  filter(study_design=="Registry report",
         grepl("Usa|Brazil|Canad", study)) %>%
  rob.summary(table = T,
              studies=.$study) %>% 
  delete_layers(idx=1:3) %>% 
  plot() + 
  geom_tile(color = "black", fill = "white", size = 1) +
  geom_point(aes(color=as.factor(measurement)), size=6, shape=15) +
  geom_text(aes(label = measurement), size = 5)


traffic_plots$reg_b <- 
  rob_data %>%
  filter(study_design=="Registry report",
         !grepl("Usa|Brazil|Canad", study)) %>%
  rob.summary(table = T,
              studies=.$study) %>%
  delete_layers(idx=1:3) +
  geom_tile(color = "black", fill = "white", size = 1) +
  geom_point(aes(color=as.factor(measurement)), size=8, shape=15) +
  geom_text(aes(label = measurement), size = 6)

ggpubr::ggarrange(plotlist = traffic_plots)

```

Let us plot the risk of bias for the studies that report incidence of NTM infection

```{r}
rob_data %>% 
  filter(grepl("Bar-On|Campos|Hatziag|Leitr", study)) %>% 
  select(-ROB_overall) %>% 
  rob.summary2(table = T,
               studies=.$study) %>% 
  delete_layers(idx = 1:3) +
  geom_tile(color = "black", fill = "white", size = 0.7) +
  geom_point(aes(color=as.factor(measurement)), size=15, shape=15) +
  geom_text(aes(label = measurement), size = 6) +
  theme(axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10))
```

Finally, for the 9 studies that reported NTM disease period prevalence and the 2 studies reporting point prevalence, I also produce a traffic light plot.

```{r}
rob_data %>%
  filter(period_disease=="yes" | grepl("Radhakrish|Bar-On", study)) %>% 
  select(-ROB_overall) %>% 
  rob.summary2(table = T,
               studies=.$study) %>% 
  delete_layers(idx = 1:3) +
  geom_tile(color = "black", fill = "white", size = 0.7) +
  geom_point(aes(color=as.factor(measurement)), size=8, shape=15) +
  geom_text(aes(label = measurement), size = 5) +
  theme(axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10)) +
  coord_flip()
```


# Exploration of period prevalence

## For infection

We will summarize:
* number of studies reporting period prevalence
* regions were they come from
* length of study period

```{r}
count(clean_data, 
      period_prevalence, period_disease)

temp$period_infection <- 
  clean_data %>% 
  filter(period_prevalence=="yes")

# region
temp$period_infection %>%  
  count_table(region1)
# population
temp$period_infection %>% 
  count_table(age_group)
#study-design
temp$period_infection %>% 
  count_table(study_design)
# study_period length
temp$period_infection %>% 
  mutate(study_length=last_year_data-first_year_data+1) %>% 
  count(study_length) %>% 
  mutate(freq=n*100/35)
# plot period prevalence values
temp$period_infection %>% 
  mutate(pp=all_ntm_infection/sample_size_cf*100) %>% 
  ggplot(data=., aes(x=0, y=pp)) +
  geom_boxplot(outlier.shape = NA, width=1) +
  geom_jitter(width=0.1) +
  xlim(-1.5, 1.5)
# sample_size
temp$period_infection %>% 
  select(sample_size_cf, study) %>%  view
# distribution of prevalence estimates
temp$period_infection %>% 
  mutate(pp=all_ntm_infection/sample_size_cf*100) %>%   
  count(pp) %>% 
  summary()
# view results according to study and time-interval
temp$period_infection %>% 
  mutate(
    study_length=last_year_data-first_year_data+1,
    pp=all_ntm_infection/sample_size_cf*100) %>% 
    select(study, study_length, pp,
           all_ntm_infection, sample_size_cf)
# overall risk of bias  
temp$period_infection %>% 
  count_table(Overall_risk)
```

## For NTM disease

```{r}
temp$period_disease<- 
  clean_data %>% 
  filter(period_disease=="yes") %>% 
  mutate(interval=last_year_data-first_year_data+1)

temp$period_disease %>% count(region1)
temp$period_disease %>% select(sample_size_cf, study) 
temp$period_disease %>% select(interval, study) 
temp$period_disease %>% count(study_design) 

```


```{r}
sessionInfo()
```

