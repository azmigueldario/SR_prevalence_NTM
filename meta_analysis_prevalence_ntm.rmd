---
title: "Analysis: systematic review of nontuberculous mycobacteria prevalence in cystic fibrosis"
author: "MDP"
date: "10/10/2021"
output: 
  html_document:
    toc: true
    toc_depth: 2
    theme: united
    number_sections: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=F)
```

# Introduction

Our systematic review is a comprehensive picture of all studies and registry reports that include prevalence/incidence of _nontuberculous mycobacteria (NTM) in cystic fibrosis_ population

The analysis will be performed in R (v4.1.1) with __Github__ version control repository.We will analyze the prevalence as a proportion and the incidence as a rate, depending on availability in results. The data from the study cohort is saved in the `input` sudirectory as a `.csv` file. 

To conduct meta-analysis of proportions, we require the following observations per study 
- _sample size_
- _study id_
- _number of events_

Other variables are included to perform complementary analyses. 

### Aims
1. Explore our data and summarize it briefly
2. Explore publication bias and produce plots
3. Conduct meta-analysis of selected studies and produce summary plots
4. Perform pre-specified subgroup analysis
5. Conduct exploratory sensitivity analysis, meta regression and hierarchical analysis

### Suggestions for analysis 


-	Contemporary cohort, maybe including only data from 2010 and onwards _#done_
- Subgroup by high quality studies according to quality appraisal _done_
- Control for overlap over years in registry studies with the random effects model (dependency in data) _#done_
- Subgroup of registry data vs peer-reviewed data _#done_
- Also, subgroup according to dates or regions _#done_
- Tips for discussion: implications of screening, raising prevalence?, implications of design, baseline status before modulators
- Contact canada/australia registries for raw numbers of NTM cases _#done, not available_
- Corroborate that the numbers in the UK and ECFS registries match _#done, numbers match properly_ 

# Data wrangling

Load required packages

- `dmetar` with its associated packages for some helpful functions 
- `meta` and `metafor` for meta-analysis, funnel plots, forest plots and meta-regression
- `knitr` allows us to produce nicely formatted tables in the report

```{r, warning=FALSE, message=FALSE}
# devtools::install_github("MathiasHarrer/dmetar")
library(dmetar)
library(meta)
library(metafor)
library(tidyverse)
library(kableExtra)
library(gginnards)
```

## Data import 

We start by importing the dataset, changing all character variables to factors and doing some cleaning. Make sure to always check that it is the latest dataset. 
- _used_registry_ contains the name of the registry used

```{r, message=FALSE}
temp <-  list()
temp$input <- 
  read_csv("./input/20211112-data_meta_analysis_qa.csv")  %>% 
  mutate(mabs_infection = as.numeric(mabs_infection),
         used_registry=fct_explicit_na(used_registry, "no")) 

# table(input_data$used_registry)
# glimpse(input_data)
```

## Data wrangling

To produce quality plots, I create a variable in the form `Author YYYY`. 
    + 

```{r study ID}
temp$untidy_data <-  
  temp$input %>% 
  mutate(
    study=gsub("([a-z])([0-9])", "\\1 \\2", id),
    # changes first letter to upper-case
    study=stringr::str_to_title(study) 
  )
```

We unify the type of study design under 3 categories and create an indicator variable for registry_report(y/n)

```{r wrangle study type}
table(temp$untidy_data$study_design)
temp$untidy_data<- 
  temp$untidy_data %>%
  mutate(
    study_design=case_when(
      study_design=="Cross-sectional study" ~ "Cross-sectional study",
      study_design=="Registry report" ~ "Registry report",
      TRUE ~ "Cohort study"),
    study_design_used.registry=case_when(
      study_design=="Registry report" | used_registry!="no" ~ "Registry report",
      TRUE ~ study_design),
    is_registry=case_when(study_design=="Registry report" ~ 1,
                          TRUE ~ 0))

temp$untidy_data %>% 
  count(is_registry, study_design, study_design_used.registry) 
```

We create a grouping variable according to the first year of data collection of a study. We use 5-years intervals between 2000 and 2020

```{r date range groups}
temp$untidy_data<- 
  temp$untidy_data %>%
  mutate(
    before_year=case_when(
      first_year_data<2000 ~ "2000 or before",
      first_year_data<=2004 ~ "2001-2004",
      first_year_data<=2009 ~ "2005-2009",
      first_year_data<=2014 ~ "2010-2014",
      TRUE ~ "2015 or after")) 

count(temp$untidy_data, before_year) 
```

The variable `region` is has some low numbers in some of the levels {AUS, ME & LAC}. For further analysis, I group them together in a single new level (others)

```{r regions}
# table(temp$untidy_data$region)

temp$untidy_data <- 
  temp$untidy_data %>% 
  mutate(region1=case_when(region=="NAM"~"NAM",
                           region=="EUR"~"EUR",
                           TRUE ~ "Other"))
#count(temp$untidy_data, region1)
```

## Cleaning quality assessment data

To plot risk of bias graphs we need a specific data structure. 

- We used the Joanna Briggs appraisal tool for prevalence studies with answer options = {Yes, No, Unclear}. Name of the variables was already cleaned in the input dataset.
- We standardize to Cochrane categories coding _Yes=Low, No=High, Unclear=Unclear_ 

```{r}
temp$untidy_data <- 
  temp$untidy_data %>% 
  mutate(across(starts_with("Q"), 
                ~ recode_factor (.x,
                                 `Yes`="Low",
                                 `Unclear`="Unclear",
                                 `No`="High",
                                 `Missing`="Missing")
                )) 
```

## Defining overall Risk of bias assessment

We will conduct a sensitivity analysis based on overall risk of bias. We make the following definitions based on the author's considerations of the most important factors in the quality appraisal:

+ **Low risk** when:
    + low risk in: sampling frame, sampling scheme, statistical calculation and NTM identification methods. 
    + NOT high risk in: standardized outcome measurement  
+ **High risk** when:
    + high risk in any of sampling frame, sampling scheme, sampling size, identification methods, statistical methods and population description
+ **Unclear** for remaining ones

I first extract the names of the columns with ROB data. When performing the case_when I shorten the names before evaluating and turn them back again after finishing. 

```{r}
temp$ROBcolnames<- 
  select(temp$untidy_data, contains("Q")) %>%
  colnames(); temp$ROBcolnames

temp$untidy_data <- 
  temp$untidy_data %>% 
  rename_with(.cols = contains("Q"), 
              ~ gsub("^(Q[0-9]).*","\\1", .x)) %>%
  mutate(
    Overall_risk=
      case_when(
        Q1=="High"|Q2=="High"|Q3=="High"|Q4=="High"|
          Q6=="High"|Q8=="High" ~ "High",
        Q1=="Low" & Q2=="Low" & Q4=="Low" & Q8=="Low" &
          Q7!="High" ~ "Low",
        TRUE ~ "Unclear")) %>%
  rename_with(.cols = matches("^Q"), ~ temp$ROBcolnames) 
```

The last step in data wrangling is to change all character variables into factors. 

```{r}
clean_data <-  
  temp$untidy_data %>%
  mutate(across(where(is.character), as_factor))
```

# Exploratory data analysis 

Let us summarize some aspects of our data. Because I will count several times, I decide to create two functions. One creates a wrapper of counting and producing a formatted table while the other ones contains only the styling steps to produce an html formatted table. 

```{r kable wrapper}
count_table <- function(data, var) {
  count(data, {{var}}) %>%
    mutate(prop = prop.table(n)*100,
           prop = round(prop, 1)) %>%
    kbl(format="html", align = c("lcc"), digits = 2, booktabs = T) %>%
    kable_styling(font_size = 25, bootstrap_options = "striped") %>% 
    kable_classic(full_width = F)
}

formatted_kable <- function(data, names=colnames(data)) {
  kbl(x=data, format="html", align = c("lccccccccc"), 
      digits=2, col.names = names) %>%
    kable_styling(font_size = 25, bootstrap_options = "striped") %>% 
    kable_classic(full_width = F)
}
```

- How many studies reported individual species data to calculate prevalence of MAC or MABs?

```{r}
clean_data %>% 
  count_table(is.na(mabs_infection))

clean_data %>% 
  count_table(is.na(avium_infection))
```


- How many studies are registry reports? 
- How many studies include pediatric, mixed or adult population ?  

```{r study types}
count_table(clean_data, study_design)

count_table(clean_data, age_group) 

# Excluding registry reports
filter(clean_data, is_registry==0) %>% 
  count_table(., age_group)
```

_ In what region where most of the studies conducted?

```{r region}
count_table(clean_data, region)
```

- Summarize the first year of data in the studies 
- What is the range of data_years included in the studies? 

```{r first year of data}

quantile(clean_data$first_year_data, na.rm = T) %>% data.frame(Quantiles=.) %>% 
  formatted_kable() 

ggplot(clean_data, aes(y=first_year_data, x=0)) +
  geom_boxplot(width=1.3, outlier.shape =NA) +
  geom_jitter(width = 0.2, color="grey37") +
  labs(title= "First year of data collected in study",
       subtitle = "All studies",
       y="") +
  theme_classic()+
  xlim(-1,1) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust=0.5),
        plot.subtitle = element_text(colour="red4"))

# excluding registry reports 
clean_data %>% 
  filter(is_registry==0) %>% 
  summarize(
    mean_year=mean(first_year_data, na.rm=T),
    sd=sd(first_year_data, na.rm=T),
    quantile_years= quantile(first_year_data, na.rm = T)
    ) %>% 
  formatted_kable()

clean_data %>% 
  filter(is_registry==0) %>% 
  ggplot(aes(y=first_year_data, x=0)) +
  stat_boxplot(geom = "errorbar", width=0.3) +
  geom_boxplot(width=1.3, outlier.shape =NA) +
  geom_jitter(width = 0.2, color="grey37") +
  labs(title= "First year of data collected in study",
       subtitle = "Excludes registry studies",
       y="") +
  theme_classic()+
  xlim(-1,1) +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.title = element_text(hjust=0.5, size=16),
        plot.subtitle = element_text(colour="red4", size=14))
```

- How many were conducted before 2010 and 2000?
    + We use the 5-year groups we previously defined to summarize this data. Before plotting, we organize in increasing order the factor variable.

```{r barplot by date range}

filter(clean_data, is_registry==0) %>%
  count_table(., before_year)

# relevel before_year factor
clean_data$before_year<- 
  factor(clean_data$before_year, levels = c("2000 or before","2001-2004","2005-2009","2010-2014","2015 or after")) 

clean_data %>% 
  filter(is_registry==0) %>%
  ggplot(aes(x=before_year, fill=factor(before_year)))+
  geom_bar() +
  labs(title= "Frequency of studies by date of data collection",
       subtitle = "No registry reports",
       x= "",
       y="") +
  scale_fill_brewer(palette = "Blues") +
  theme_classic()+
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, size=16),
        plot.subtitle = element_text(color="red4", size=14),
        axis.text = element_text(size=12)) 
```

- What is the median sample size of the non-registry studies?
    + Does this change according to the year of data collection?

```{r sample size}
## for registry reports or registry based studies
clean_data %>% 
  filter(is_registry==1 | used_registry=="yes") %>% 
  summarize(
  SampleSize_quantiles=quantile(sample_size_cf, na.rm=T)) %>% 
  formatted_kable()

# observational studies
clean_data %>% 
  filter(is_registry==0 & used_registry=="no") %>% 
  summarize(
  sample_size_quantiles=quantile(sample_size_cf, na.rm=T)) %>%
  formatted_kable()

clean_data %>% 
  filter(is_registry==0 & used_registry=="no") %>% 
  ggplot(aes(y=sample_size_cf, x=first_year_data)) +
  geom_point(size=2) +
  labs (title="Sample size according to year of data",
       subtitle="No registry reports",
       x="First year of data collection",
       y="CF sample size (log10 scale)") +
  scale_y_continuous(trans="log10") +
  theme(plot.subtitle = element_text(color="red4", size = 14),
        plot.title = element_text(size=16, hjust=0.5),
        axis.text = element_text(size=12),
        axis.title = element_text(size=12)) 
```

## How many studies report every outcome

In this dataset, only data that could be summarized through meta-analysis was incldued, requires raw events and raw total or proportion with 95% CI

* __NTM disease__
    + Period prevalence = 9
    + Point prevalence = 1
* NTM infection
    + Incidence proportion = 4
    + Point prevalence = 46
    + Period prevalence = 27

```{r}
clean_data %>% 
  filter(!is.na(all_ntm_infection)) %>%
  mutate(point=case_when(
    last_year_data - first_year_data < 2 ~ "yes",
    TRUE ~ "no" )) %>%
  count_table(point)
```

# Meta analysis of NTM infection prevalence (point)

### Wrapper functions for meta analysis and forest plots 

Before starting and because we will be producing multiple meta-analysis, I decided to create two functions to standardize our approach to meta-analysis in this data set. 

The first function wraps the `meta::metaprop` function with options 
 - `sm=PLOGIT` specifies to use the logit transformation for the proportions
 - `hakn=TRUE` applies an adjustment for more conservative confidence intervals
 - `comb.random=T` specified a random effects model
 - `method="GLMM"` recommended over inverse variance for proportions
 - Sample size is in variable `sample_size_cf` and number of events in `all_ntm_infection`

```{r formatted meta.prop function}
metaprop_formatted <- function (data=data, fixed=F){
  metaprop(
    data=data,
    event = all_ntm_infection,
    n = sample_size_cf,
    studlab = study,
    method = "GLMM",
    sm = "PLOGIT",
    random = TRUE,
    fixed=fixed,
    hakn = TRUE)
}
```

We will also produce numerous forest plots, to avoid repeating code I create a wrapper function that specifies the most common formating arguments to use. 
- `sortvar` is the sorting variable, by default it is the weigth in the MA
- `predict=T` calculates prediction intervals instead of CI
- `comb.fixed = F` translates to random effects MA
- `print.I2.ci = T` forces printing of heterogeneity confidence intervals
- `study.results` determines if individual study results should be plotted
- We also specify to format output according to RevMan5 style and adjust some graphical properties like space, color and type of statistical test. 
- X-axis limit and some of the titles can also be added in the plot. 

```{r formatted forest.meta }

forest_wrapper <- function(
  data, sort.var=data$TE, stu.res=F,
  xlim=c(0,0.5), pred_int=T,
  subgroup.name="", xlab="") {
  
  forest.meta(x=data,
    sortvar = sort.var,
    predict = pred_int,
    comb.fixed = F,
    layout="RevMan5",
    print.I2.ci = T,
    colgap.left = "2cm",
    colgap.forest = "1.5cm",
    rightcols = c("effect", "ci", "w.random"),
    study.results = stu.res,
    test.subgroup.random = T,
    addrow.subgroups = T,
    addrow = T,
    addrow.overall = T,
    col.by = "grey2",
    test.subgroup = T,
    xlab = xlab,
    xlim=xlim,
    addrows.below.overall = 1,
    subgroup.name = subgroup.name
    )
}
# forest_wrapper(meta.full)

```

## All studies meta-analysis

* Meta-analysis will be conducted only for point prevalence of NTM infection
    - Numerator: `all_ntm_infection` which contains the number of events
    - Denominator: `sample_size_cf`
    - Period prevalence may have variable intervals and cannot be easily merges, will be summarized in tables

* For analysis, we create a dataset that includes only the set of studies to analyze (n=73)

```{r}
inf_point_data <-  
  clean_data %>% 
  filter (!is.na(all_ntm_infection) &
           last_year_data - first_year_data < 2) 
```

Our first meta-analysis includes all available studies, shows high heterogeneity and all observations cannot be included in plot. 

```{r}
meta.full<- metaprop_formatted(inf_point_data)

# print.meta(meta.full)

forest_wrapper(meta.full)
```

The results using the metafor package and the same conditions are roughly the same. See below. 

## Subgroup according to study design (registry or not) 

We use the `meta` package to produce quality forest plots for publication. We just have to update our `full.meta` object according to each subgroup and adjust the plotting qualities. 

```{r}
update.meta(meta.full,
            subgroup = is_registry, 
            tau.common = F)
# Subgroup test is significant but not relevant because the change is (98.5 vs 99.8)

update.meta(meta.full,
            subgroup = study_design_used.registry, 
            tau.common = F) 
# reduced heterogeneity according to study design, lower in cohort studies (82% vs 99%)
```
 
Here, we print the forest plot for the subgroup analysis according to _study_design_ with  prediction intervals under the subgroup analysis. 

```{r}
update.meta(meta.full,
            subgroup = study_design, 
            tau.common = F) %>% 
forest_wrapper(data =.)

update.meta(meta.full,
            subgroup = study_design_used.registry, 
            tau.common = F) %>% 
forest_wrapper(data =.)


inf_point_data %>% 
  filter(used_registry!="Brazil") %>% 
  metaprop_formatted() %>% 
  update.meta(.,
            subgroup =  study_design,
            tau.common = F) %>% 
  forest_wrapper()

```

### Separated forest plots for registry studies and observational studies

* Some Canadian and Australian reports only had proportion and not raw numbers
```{r}
inf_point_data %>% 
  filter (is_registry==1) %>% 
  metaprop_formatted(data=.) %>% 
  forest_wrapper(data=., stu.res = T, xlim = c(0,0.3))
```

* Only observational studies, excluding those that used registry data

```{r}
inf_point_data %>% 
  filter (is_registry==0) %>%
  metaprop_formatted(data=.) %>%
  forest_wrapper(data=., stu.res = T, 
                 sort.var = .$studlab, xlim = c(0,0.35))

```

## According to the year of data collection

```{r}
update.meta(meta.full,
            subgroup = before_year, 
            tau.common = F) %>%
  forest_wrapper(data=., pred_int = F, xlim=c(0,1), 
                 subgroup.name="First year of data collection", )

```
Here, we see reduced heterogeneity in the groups before 2000, 2001 - 2004 and 2005 - 2009. 
The omnibus test shows us that there is a significant reduction in the heterogeneity due to when the data was collected. 

## Subgroup by regions (continents)

We had previously coded North America (NAM) as the reference region. We see that numbers in Australia (AUS) and the Middle-East (ME) are pretty low so we recode them as part of the others group with the Latin-American (LAC) studies.

```{r}
update.meta(meta.full,
            subgroup =  region1, 
            tau.common = F) %>% 
  forest_wrapper(data=., subgroup.name ="Region", 
                 pred_int = T, xlim = c(0,0.5))
    
```

We can also see that there is a significant difference in the effect estimates among the groups. However, the heterogeneity has not changed significantly according to this. 

**Subgroup by age** 
- Not performed because more than 80% of the studies have a mixed (pediatric+adult) population and is impossible to extract exact numbers from it


## Meta-regression: including multiple moderators 

In the `metafor` package, we can use the `rma.uni` function to fit almost all meta-analyses and indicate the moderators (grouping variables) to be used. 

Syntax options for moderators:
 - mods = cbind(mod1,mod2,mod3)
 - mods= ~ mod1 + mod2 + mod3


1. Calculate the effect size (proportions) using `escalc()` 
    + Reorder and format covariates
    + Our units are Logit-proportions **"PLO"** as they have better statistical characteristics _(Schwarzer 2019)_
    + All co-variates are inside the `inf_point_data` object

```{r calculate proportion effect size}
# relevel reference in factors
inf_point_data <- 
  inf_point_data %>% 
  mutate(region1=relevel(region1, ref="NAM"),
         before_year=relevel(before_year, ref="2015 or after"),
         study_design=relevel(study_design, ref="Registry report")) 

inf_point_escalc<- 
inf_point_data  %>% 
  escalc(
    data = .,
    xi=all_ntm_infection, # number of events
    ni=sample_size_cf,  # sample size
    measure="PLO")
```

2. Validate results between `meta` and `metafor`by fitting general meta-analysis
    +  *slab*= study label
    + *yi & vi* are effect measures calculated by `escalc()`
    + *method*= REML

```{r metafor all studies MA}
metafor.full <- 
  rma.uni(
  yi = yi, 
  vi = vi, 
  slab = id,
  data = inf_point_escalc,
  test = "knha",
  method = "REML")

meta.full$TE.random %>% transf.ilogit()
coef(metafor.full) %>% transf.ilogit()

# provides roughly the same results
```

3. Fit a meta-regression model to evaluate the heterogeneity according to our pre-specified subgroups
    + Establish reference level for factor variables
```{r meta-regression}

metareg <- 
  rma.uni(
  yi = yi, 
  vi = vi,
  mods= ~ region1 + before_year + study_design +study_design*region1, 
  slab = id,
  data = inf_point_escalc,
  test = "knha",
  method = "REML"
  )

# create vector with formatted names for coefficients
temp$coef.names <- 
  c("Intercept", "EUR:region", "Other:region", 
    "2000 or before", "2001-2004", "2005-2009",
    "2010-2014", "Cross.sectional:design", "Cohort:design",
    "EUR*Cross.sectional", "Other*Cross.sectional", "EUR*Cohort")

# backtransform LOGIT proportions
# produce nice table
summary(metareg) %>% 
  coef() %>% 
  mutate(Coefs=temp$coef.names,.before=1
         ) %>%
  remove_rownames() %>% 
  formatted_kable(names=c("Coefficients", "LOGIT-estimate", "std.error", 
                          "t-value", "df", "p.value", "CI-lower",
                          "CI-upper")) %>% 
  row_spec(row=c(2,3,7,11), bold=T) %>% 
  kable_styling(font_size = 18)

  col
  kbl( format = "html", align="c", digits = 3, full_width=F, row.names = T) %>% 
  kable_styling(font_size = 30, bootstrap_options = "striped") %>% 
    kable_classic() 
  
```



# Exploratory meta-analyses

## Multilevel model

Registry studies may have large collinearity and overlap of subjects. We explored if this dependency is a source of heterogeneity through a multi-level meta-analysis. 


* `rma.mv()` fits multilevel meta-analysis 
    +`random = ~ 1 | a/b` specifies b nested in a
    +`random = ~ a | b ` specifies that a as inner group and b as outer group

```{r}
# table(inf_point_data$used_registry)

multilvl.meta <- 
  rma.mv(yi = yi, 
         V = vi,
         slab = id,
         data = inf_point_escalc,
         random = ~ 1 | used_registry/id,
         test = "t",
         method = "REML")
data.frame(
  Estimate=transf.ilogit(multilvl.meta$beta),
  Lower_CI=transf.ilogit(multilvl.meta$ci.lb),
  Upper_CI=transf.ilogit(multilvl.meta$ci.ub)) %>% 
  kbl( format = "html", align="c", digits = 3, full_width=F, row.names = F) %>% 
  kable_styling(font_size = 30, bootstrap_options = "striped") %>% 
    kable_classic() 

summary(multilvl.meta)
transf.ilogit(-3.2488)
```

Now, lets evaluate the variance explained by every level of our hierarchical model. 
Level 3 is the level where we grouped according to registry. 

```{r}
var.comp(multilvl.meta)$results %>%
  mutate(Vars=c("Individual level", "Study/registry", "Registry"),
         n_groups=c("--", "73", "6"),
         .before=1) %>% 
  formatted_kable(names = c("", "n", "% of total variance", "$I^2$")) %>% 
  row_spec(row = 0, bold = T) %>% 
  kable_styling(font_size = 24)
```

## Subgroup according to overall quality assessment

We also conduct a subgroup analysis to evaluate if there are different estimates of prevalence of NTM infection according to the Overall risk of bias determined by the JBI tool

```{r}
table(inf_point_data$Overall_risk)

update.meta(meta.full,
            subgroup =  Overall_risk, 
            tau.common = F)
```

The statistical test shows that there is significant difference according to the risk of bias appraisal. We also see that differences in the Low risk group are minimal and may provide a good accuracy of the NTM prevalence.

```{r}
update.meta(meta.full,
            subgroup = Overall_risk, 
            tau.common = F) %>%
  forest_wrapper(subgroup.name = "Overall Risk of Bias (JBI)")

```

To finalize these subgroup analyses, I will plot only the low risk of bias studies. 

```{r}
inf_point_data %>% 
  filter(Overall_risk=="Low") %>%
  metaprop_formatted(data=.) %>% 
  forest_wrapper(stu.res = T, xlim = c(0,0.3), sort.var = .$stulab)
  
```


# Complementary analyses for meta-analysis

## Publication bias (funnel plot)

For the meta-analysis of all studies (contour-enhanced funnel plot)

```{r all studies funnel plot and egger's test}
funnel(x=metafor.full,
       xlab="Logit transformed proportions",
       level=c(90, 95, 99), 
       shade=c("white", "gray55", "gray75"),
       legend="topleft", 
       atransf = transf.ilogit)

regtest(metafor.full,
        model = "rma",
        predictor = "sei",
        ret.fit = T)

# for the metaregression 
regtest(metareg,
        model = "rma",
        predictor = "sei",
        ret.fit = T
        )

```

There is a significant p_value including all studies (p=0.0088), and  we can see an asymmetry at the lower left side (low SE and small estimate) which probably correspond to the Brazilian registry reports

```{r excluding Brazil registry (funnel & egger's test)}

temp$maetafor_not_brazil <- 
inf_point_data  %>% 
  filter(used_registry!="Brazil") %>% 
  escalc(
    data = .,
    xi=all_ntm_infection, # number of events
    ni=sample_size_cf,  # sample size
    measure="PLO") %>%
  rma.uni(
    yi = yi,
    vi = vi,
    slab = id,
    data = .,
    test = "knha",
    method = "REML")


funnel(x=temp$maetafor_not_brazil,
       xlab="Logit transformed proportions",
       level=c(90, 95, 99), 
       shade=c("white", "gray55", "gray75"),
       legend="topleft", 
       atransf = transf.ilogit)
regtest(temp$maetafor_not_brazil,
        model = "rma",
        predictor = "sei",
        ret.fit = T)
```

If we exclude these reports, the asymmetry is removed and the p-value turns non-significant. These reports have a poor screening rate, but report the prevalence as if all subjects were studied. 

## Publication bias (Trim & Fill method)

The trim and fill method detects places of asymmetry in the funnel plot and inputs studies to achieve a more balanced estimation. It is used to quantify the degree of small studies bias in our results. 

```{r}
trimfill(metafor.full)

# backtransform logit to proportion
transf.ilogit(-2.7489)
```

No study was imputed using these method and the estimate did not change at all. 

## Pubication bias (p-value curves)

Mostly used for association studies, where the studies tend to be published if the correlation or effect measure is beyond the significance treshold. If a significant association is actually there, we expect a p-value way below the significance value (like 0.0001 or 0.003 instead of 0.048 or 0.047). 

Thus, we can see the distribution of p-values inside the cohort of studies. 

```{r}
pcurve(meta.full)
```

However, because our meta-analysis is of proportions, the p-value may not be a representative indication of why it is published or not, despite its relationship with the sample size. 

```{r, eval=FALSE}
# publication bias based on p-values seems counter-intuitive for prevalence studies
metafor::selmodel(metafor.full,
                  type = "stepfun",
                  steps = 0.5,
                  verbose=T)
```

# Risk of bias appraissal

We will summarize the Quality assessment recorded from the Joanna Briggs tool. Unfortunately, there is no easy way to plot this in R and we have to create a new dataframe that fulfills the requirements of the available tools:

- First column for study labels named `study`
- Then, columns with the risk of bias appraisal coded as Low/Unclear/High and Missing
- Overall quality in last column

```{r load robvis library, message=F}
# must be latest development version, used 0.3.0.900
# install.packages("devtools")
# devtools::install_github("mcguinlu/robvis")
# library (robvis)
```

First, we select only the variables that contain quality assessment data and transform the data into a `data.frame` object.

We define studies with Low risk of bias as those with an adequate sampling frame, taken from a census or a random sampling, having properly described identification methods and reporting of statistical measures

```{r}
rob_data <- 
  clean_data %>% 
  select(study, matches("Q[0-9]"), Overall_risk, 
         study_design, before_year, period_disease, period_prevalence) %>% 
  rename(ROB_overall=Overall_risk) %>% 
  as.data.frame() 
```

## Summary plots

Now, we produce both plots summary tables using the rob.summary function from the `dmetar` package

* The function had a minor issue with the matching of the legend so I correct it in the source code as rob.summary2
 - All credit to authors, I will just use it locally

```{r rob.summary2}
rob.summary2 = function(data,
                       name.high="High",
                       name.unclear="Unclear",
                       name.low="Low",
                       studies,
                       name.missing,
                       table = FALSE){
  
  # Class Checks
  if (class(data) != "data.frame"){
    stop("'data' must be of class 'data.frame'.")
  }
  
  
  if (missing(name.missing)){
    
    # Only select columns with RoB data
    
    colnames.rob = character()
    
    for (i in 1:ncol(data)){
      
      vect = as.character(data[,i])
      
      for (j in 1:length(data[,i])){
        
        if (vect[j] %in% c(name.high, name.unclear, name.low)){
          
          colnames.rob[i] = TRUE
          
        } else {
          
          colnames.rob[i] = FALSE
          message(cat("Column '", colnames(data)[i],
                      "' removed from plot because it did not contain the specified RoB ratings (only). \n",
                      sep=""))
          break
          
        }
      }
    }
    
    # Use mask: rob data
    rob = data[ , as.logical(colnames.rob)]
    
    # Relevel for plot
    for (i in 1:ncol(rob)){
      
      rob[,i] = as.character(rob[,i])
      rob[rob[,i]==name.high,i] = "High"
      rob[rob[,i]==name.unclear,i] = "Unclear"
      rob[rob[,i]==name.low,i] = "Low"
      
    }
    
    # Make table
    if (table == TRUE){
      
      if (missing(studies)){
        stop("'studies' has to be specified when 'table = TRUE'.")
      }
      
      if (length(as.vector(studies)) != nrow(data)){
        stop("'studies' vector is not of equal length as the data.")
      }
      
      if (length(unique(studies)) != length(studies)){
        stop("'studies' cannot contain duplicate study labels.")
      }
      
      robby = rob
      robby = data.frame(study = studies,
                         condition = rep(colnames(robby), each = length(studies)),
                         measurement = unlist(robby))
      rownames(robby) = NULL
      robby$condition = gsub("_"," ", robby$condition)
      robby$condition = gsub("-"," ", robby$condition)
      robby$condition = gsub("\\."," ", robby$condition)
      robby[robby$measurement=="Low", "measurement"] = "+"
      robby[robby$measurement=="Unclear", "measurement"] = "?"
      robby[robby$measurement=="High", "measurement"] = "-"
      
      # Order factor
      robby$study = factor(robby$study,
                           levels = unique(studies)[rev(order(unique(robby$study)))])
      
      
      rob.table = ggplot(data = robby, aes(y = study, x = condition)) +
        geom_tile(color="black", fill="white", size = 0.8) +
        geom_point(aes(color=as.factor(measurement)), size=20) +
        geom_text(aes(label = measurement), size = 8) +
        scale_x_discrete(position = "top") +
        scale_color_manual(values = c("?" = "#E2DF07",
                                      "-" = "#BF0000",
                                      "+" = "#02C100")) +
        theme_minimal() +
        coord_equal() +
        theme(axis.title.x = element_blank(),
              axis.title.y = element_blank(),
              axis.ticks.y = element_blank(),
              axis.text.y = element_text(size = 15, color = "black"),
              axis.text.x = element_text(size = 13, color = "black", angle = 90, hjust=0),
              legend.position = "none",
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.background = element_blank())
      
    }
    
    # Make long format, clean the factors
    rob.long = data.frame(condition = rep(colnames(rob), each = nrow(rob)),
                          measurement = unlist(rob))
    rownames(rob.long) = NULL
    rob.long$condition = gsub("_"," ",rob.long$condition)
    rob.long$condition = gsub("-"," ",rob.long$condition)
    rob.long$condition = gsub("\\."," ",rob.long$condition)
    rob.long$measurement = as.factor(rob.long$measurement)
    rob.long$measurement = factor(rob.long$measurement, levels(rob.long$measurement)[c(1, 3, 2)])
    
    # Make plot
    rob.plot = ggplot(data = rob.long) +
      geom_bar(mapping = aes(x = condition, fill = measurement), width = 0.7,
               position = "fill", color = "black") +
      coord_flip(ylim = c(0, 1)) +
      guides(fill = guide_legend(reverse = TRUE)) +
      scale_fill_manual("Risk of Bias",
                        labels = c("    Unclear risk of bias       ",
                                   "    High risk of bias          ",
                                   "    Low risk of bias  "),
                        values = c(Unclear = "#E2DF07", High = "#BF0000", Low = "#02C100")) +
      scale_y_continuous(labels = scales::percent) +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.text.y = element_text(size = 18, color = "black"),
            axis.line.x = element_line(colour = "black", size = 0.5, linetype = "solid"),
            legend.position = "bottom",
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.background = element_rect(linetype = "solid", colour = "black"),
            legend.title = element_blank(),
            legend.key.size = unit(0.75, "cm"),
            legend.text = element_text(size = 14))
    
    plot(rob.plot)
    
    if (table == TRUE){
      plot(rob.table)
    }
    
  } else {
    
    # Only select columns with RoB data
    data = as.data.frame(data)
    
    colnames.rob = character()
    
    for (i in 1:ncol(data)){
      
      vect = as.character(data[,i])
      
      for (j in 1:length(data[,i])){
        
        if (vect[j] %in% c(name.high, name.unclear, name.low, name.missing)){
          
          colnames.rob[i] = TRUE
          
        } else {
          
          colnames.rob[i] = FALSE
          message(cat("Column '", colnames(data)[i],
                      "' removed from plot because it did not contain the specified RoB ratings (only). \n",
                      sep=""))
          break
          
        }
      }
    }
    
    # Use mask: rob data
    rob = data[ , as.logical(colnames.rob)]
    
    # Relevel for plot
    for (i in 1:ncol(rob)){
      
      rob[,i] = as.character(rob[,i])
      rob[rob[,i]==name.high,i] = "High"
      rob[rob[,i]==name.unclear,i] = "Unclear"
      rob[rob[,i]==name.low,i] = "Low"
      rob[rob[,i]==name.missing,i] = "Missing"
      
    }
    
    # Make Table
    
    if (table == TRUE){
      
      if (missing(studies)){
        stop("'studies' has to be specified when 'table = TRUE'.")
      }
      
      if (length(as.vector(studies)) != nrow(data)){
        stop("'studies' vector is not of equal length as the data.")
      }
      
      robby = rob
      robby = data.frame(study = as.factor(studies),
                         condition = rep(colnames(robby), each = length(studies)),
                         measurement = unlist(robby))
      rownames(robby) = NULL
      robby$condition = gsub("_"," ", robby$condition)
      robby$condition = gsub("-"," ", robby$condition)
      robby$condition = gsub("\\."," ", robby$condition)
      robby[robby$measurement=="Low", "measurement"] = "+"
      robby[robby$measurement=="Unclear", "measurement"] = "?"
      robby[robby$measurement=="High", "measurement"] = "-"
      robby[robby$measurement=="Missing", "measurement"] = " "
      
      # Order factor
      robby$study = factor(robby$study,
                           levels = unique(studies)[rev(order(unique(robby$study)))])
      
      rob.table = ggplot(data = robby, aes(y = study, x = condition)) +
        geom_tile(color="black", fill="white", size = 0.8) +
        geom_point(aes(color=as.factor(measurement)), size=20) +
        geom_text(aes(label = measurement), size = 8) +
        scale_x_discrete(position = "top") +
        scale_color_manual(values = c("?" = "#E2DF07",
                                      "-" = "#BF0000",
                                      "+" = "#02C100",
                                      " " = "white")) +
        theme_minimal() +
        coord_equal() +
        theme(axis.title.x = element_blank(),
              axis.title.y = element_blank(),
              axis.ticks.y = element_blank(),
              axis.text.y = element_text(size = 15, color = "black"),
              axis.text.x = element_text(size = 13, color = "black", angle = 90, hjust=0),
              legend.position = "none",
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.background = element_blank())
      
    }
    
    
    # Make long format, clean the factors
    rob.long = data.frame(condition = rep(colnames(rob), each = nrow(rob)),
                          measurement = unlist(rob))
    rownames(rob.long) = NULL
    rob.long$condition = gsub("_"," ",rob.long$condition)
    rob.long$condition = gsub("-"," ",rob.long$condition)
    rob.long$condition = gsub("\\."," ",rob.long$condition)
    rob.long$measurement = as.factor(rob.long$measurement)
    rob.long$measurement = factor(rob.long$measurement, levels(rob.long$measurement)[c(3,1,4,2)])
    
    rob.plot = ggplot(data = rob.long) +
      geom_bar(mapping = aes(x = condition, fill = measurement), width = 0.7,
               position = "fill", color = "black") +
      coord_flip(ylim = c(0, 1)) +
      guides(fill = guide_legend(reverse = TRUE)) +
      scale_fill_manual("Risk of Bias",
                        labels = c("  Unclear risk of bias  ",
                                   "  High risk of bias   ",
                                   "  Low risk of bias  ",
                                   "  Missing information  "),
                        values = c(Unclear = "#E2DF07",
                                   High = "#BF0000",
                                   Low = "#02C100",
                                   Missing = "white")) +
      scale_y_continuous(labels = scales::percent) +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.text.y = element_text(size = 18, color = "black"),
            axis.line.x = element_line(colour = "black", size = 0.5, linetype = "solid"),
            legend.position = "bottom",
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.background = element_rect(linetype = "solid", colour = "black"),
            legend.title = element_blank(),
            legend.key.size = unit(0.75, "cm"),
            legend.text = element_text(size = 14))
    
    plot(rob.plot)
    
    if (table == TRUE){
      plot(rob.table)
    }
    
  }
  
}

```


All studies inside the summary

```{r}
rob_data %>%
  select(-ROB_overall) %>% 
  rob.summary2(data=.,
              name.high="High",
              name.unclear="Unclear",
              name.low="Low",
              name.missing ="Missing",
              studies=.$study) 

```

Registry studies vs others

```{r}
rob_data %>%
  filter(study_design=="Registry report") %>% 
  select(-ROB_overall) %>% 
  rob.summary2(data=.,
              name.high="High",
              name.unclear="Unclear",
              name.low="Low",
              name.missing ="Missing",
              studies=.$study)

rob_data %>%
  filter(study_design!="Registry report") %>% 
  select(-ROB_overall) %>% 
  rob.summary2(data=.,
              name.high="High",
              name.unclear="Unclear",
              name.low="Low",
              name.missing ="Missing",
              studies=.$study)

```

Another outcome with multiple studies is NTM infection prevalence, so I summarize it in a barplot

```{r}

```


## Traffic light plots

We summarize as subgroups to avoid crowding in the plot, so I produce first traffic plots for all registry reports. 

* Using the `delete_layers()` I remove automatically generated layers so they are not seen in the background
* Then, I add the table layout, color squares and text to produce the traffic light

```{r}

traffic_plots <- list()
traffic_plots$reg_a <- 
  rob_data %>%
  filter(study_design=="Registry report",
         grepl("Usa|Brazil|Canad", study)) %>%
  rob.summary(table = T,
              studies=.$study) %>% 
  delete_layers(idx=1:3) %>% 
  plot() + geom_tile(color = "black", fill = "white", size = 1) +
  geom_point(aes(color=as.factor(measurement)), size=6, shape=15) +
  geom_text(aes(label = measurement), size = 5)


traffic_plots$reg_b <- 
  rob_data %>%
  filter(study_design=="Registry report",
         !grepl("Usa|Brazil|Canad", study)) %>%
  rob.summary(table = T,
              studies=.$study) %>%
  delete_layers(idx=1:3) +
  geom_tile(color = "black", fill = "white", size = 1) +
  geom_point(aes(color=as.factor(measurement)), size=8, shape=15) +
  geom_text(aes(label = measurement), size = 6)

ggpubr::ggarrange(plotlist = traffic_plots)

```

Let us plot the risk of bias for the studies that report incidence of NTM infection

```{r}
rob_data %>% 
  filter(grepl("Bar-On|Campos|Hatziag|Leitr", study)) %>% 
  select(-ROB_overall) %>% 
  rob.summary2(table = T,
               studies=.$study) %>% 
  delete_layers(idx = 1:3) +
  geom_tile(color = "black", fill = "white", size = 0.7) +
  geom_point(aes(color=as.factor(measurement)), size=12, shape=15) +
  geom_text(aes(label = measurement), size = 6) +
  theme(axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10))
```

Finally, for the 9 studies that reported NTM disease period prevalence and the 2 studies reporting point prevalence, I also produce a traffic light plot.

```{r}
rob_data %>%
  filter(period_disease=="yes" | grepl("Radhakrish|Bar-On", study)) %>% 
  select(-ROB_overall) %>% 
  rob.summary2(table = T,
               studies=.$study) %>% 
  delete_layers(idx = 1:3) +
  geom_tile(color = "black", fill = "white", size = 0.7) +
  geom_point(aes(color=as.factor(measurement)), size=8, shape=15) +
  geom_text(aes(label = measurement), size = 5) +
  theme(axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=10)) +
  coord_flip()
```


# Exploration of period prevalence

## For infection

We will summarize:
* number of studies reporting period prevalence
* regions were they come from
* length of study period

```{r}
count(clean_data, 
      period_prevalence, period_disease)

temp$period_infection <- 
  clean_data %>% 
  filter(period_prevalence=="yes")

# region
temp$period_infection %>%  
  count_table(region1)
# population
temp$period_infection %>% 
  count_table(age_group)
#study-design
temp$period_infection %>% 
  count_table(study_design)
# study_period length
temp$period_infection %>% 
  mutate(study_length=last_year_data-first_year_data+1) %>% 
  count(study_length) %>% 
  mutate(freq=n*100/35)
# plot period prevalence values
temp$period_infection %>% 
  mutate(pp=all_ntm_infection/sample_size_cf*100) %>% 
  ggplot(data=., aes(x=0, y=pp)) +
  geom_boxplot(outlier.shape = NA, width=1) +
  geom_jitter(width=0.1) +
  xlim(-1.5, 1.5)
# sample_size
temp$period_infection %>% 
  select(sample_size_cf, study) %>%  view
# distribution of prevalence estimates
temp$period_infection %>% 
  mutate(pp=all_ntm_infection/sample_size_cf*100) %>%   
  count(pp) %>% 
  summary()
# view results according to study and time-interval
temp$period_infection %>% 
  mutate(
    study_length=last_year_data-first_year_data+1,
    pp=all_ntm_infection/sample_size_cf*100) %>% 
    select(study, study_length, pp,
           all_ntm_infection, sample_size_cf)
# overall risk of bias  
temp$period_infection %>% 
  count_table(Overall_risk)
```

## For NTM disease

```{r}
temp$period_disease<- 
  clean_data %>% 
  filter(period_disease=="yes") %>% 
  mutate(interval=last_year_data-first_year_data+1)

temp$period_disease %>% count(region1)
temp$period_disease %>% select(sample_size_cf, study) 
temp$period_disease %>% select(interval, study) 
temp$period_disease %>% count(study_design) 

```


```{r}
sessionInfo()
```

